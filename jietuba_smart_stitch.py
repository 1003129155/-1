"""
jietuba_smart_stitch.py - æ™ºèƒ½å›¾ç‰‡æ‹¼æ¥æ¨¡å—

ä½¿ç”¨ORBç‰¹å¾ç‚¹åŒ¹é… + RANSACï¼Œè‡ªåŠ¨è¯†åˆ«é‡å åŒºåŸŸå¹¶æ™ºèƒ½æ‹¼æ¥
è¿™æ˜¯ä¸“ä¸šå›¾åƒæ‹¼æ¥è½¯ä»¶çš„æ ‡å‡†æ–¹æ³•ï¼ˆPhotoshopã€Huginç­‰éƒ½ç”¨è¿™ä¸ªï¼‰

æœ€æ–°ä¼˜åŒ–ç‰ˆæœ¬ - 2025-10-29 Yè½´å‡ ä½•çº¦æŸå‡çº§ç‰ˆ
================================

ğŸ¯ æ–°å¢åŠŸèƒ½ (2025-10-29):
  â­ Yè½´å‡ ä½•çº¦æŸéªŒè¯
     - æ£€æµ‹è§„åˆ™ï¼šYè½´åç§»ä¸åº”ä¸ºè´Ÿæ•°ï¼ˆé•¿æˆªå›¾å‘ä¸‹æ»šåŠ¨ï¼Œä¸ä¼šå‘ä¸Šï¼‰
     - å¼‚å¸¸æ£€æµ‹ï¼šå½“median_offset < -10pxæ—¶ï¼Œè‡ªåŠ¨è§¦å‘å¤‡é€‰æ–¹æ¡ˆ
     - å¤šç­–ç•¥é‡è¯•ï¼šæ ‡å‡†æœç´¢ â†’ æ‰©å¤§æœç´¢ â†’ å…¨å›¾æœç´¢ â†’ æ¨¡æ¿åŒ¹é…
     - æé«˜å‡†ç¡®æ€§ï¼šé¿å…è¯¯æ£€æµ‹å¯¼è‡´çš„é”™è¯¯æ‹¼æ¥

  â­ è‡ªåŠ¨è¿‡æ»¤é‡å¤å›¾ç‰‡
     - æ£€æµ‹è§„åˆ™ï¼šå¦‚æœå›¾iä¸å›¾i+1çš„é‡å¤ç‡>60%ï¼Œä¸”å›¾iä¸å›¾i+2çš„é‡å¤ç‡>20%ï¼Œåˆ™è·³è¿‡å›¾i+1
     - åº”ç”¨åœºæ™¯ï¼šç½‘é¡µæ»šåŠ¨æˆªå›¾æ—¶çš„é‡å¤å¸§ã€åŠ¨æ€å¹¿å‘Šå¯¼è‡´çš„é‡å¤å†…å®¹
     - æé«˜æ‹¼æ¥è´¨é‡ï¼Œå‡å°‘å†—ä½™å†…å®¹

  â­ ä¸¤ä¸¤é…å¯¹æ‹¼æ¥ç­–ç•¥ (pairwise) - 
     - åˆ†æ²»æ³•ï¼šæ¯è½®å°†ç›¸é‚»å›¾ç‰‡ä¸¤ä¸¤é…å¯¹æ‹¼æ¥
     - ä¼˜åŠ¿ï¼šå›¾ç‰‡å¤§å°ç›¸è¿‘ï¼Œç‰¹å¾ç‚¹åˆ†å¸ƒå‡è¡¡ï¼Œå‡å°‘ç´¯ç§¯è¯¯å·®
     - ç¤ºä¾‹ï¼š8å¼ å›¾ â†’ 4å¼  â†’ 2å¼  â†’ 1å¼ 
  
  ğŸ“Œ ä¿ç•™ä¼ ç»Ÿç­–ç•¥ (sequential)
     - é¡ºåºç´¯ç§¯æ‹¼æ¥
     - é€‚ç”¨äºç®€å•åœºæ™¯

æ ¸å¿ƒç®—æ³•:
  âœ… ORBç‰¹å¾ç‚¹åŒ¹é… - å¿«é€Ÿã€é²æ£’
  âœ… Yè½´å‡ ä½•çº¦æŸ - ğŸ†• é˜²æ­¢è´Ÿæ•°åç§»çš„è¯¯æ£€æµ‹
  âœ… å¤šç­–ç•¥é‡è¯•æœºåˆ¶ - ğŸ†• è‡ªåŠ¨æ‰©å¤§æœç´¢èŒƒå›´
  âœ… é‡å¤å›¾ç‰‡æ£€æµ‹ - è‡ªåŠ¨è¿‡æ»¤å†—ä½™å¸§
  âœ… è‡ªé€‚åº”ç‰¹å¾æ£€æµ‹ - æ ¹æ®çº¹ç†ä¸°å¯Œåº¦è‡ªåŠ¨è°ƒæ•´ç­–ç•¥
  âœ… MAD-based RANSAC - æ›´é²æ£’çš„å¼‚å¸¸å€¼è¿‡æ»¤
  âœ… å‡ ä½•çº¦æŸéªŒè¯ - Xè½´åç§»çº¦æŸ(å‚ç›´æ‹¼æ¥)
  âœ… å¤šç»´åº¦ç½®ä¿¡åº¦è¯„ä¼° - 6ä¸ªç»´åº¦ç»¼åˆè¯„åˆ†
  âœ… æ¨¡æ¿åŒ¹é…åå¤‡ - ç‰¹å¾ç‚¹å¤±è´¥æ—¶è‡ªåŠ¨é™çº§

ä¼˜åŒ–ç‚¹:
  ğŸš€ Yè½´çº¦æŸ: ğŸ†• æ£€æµ‹è´Ÿæ•°åç§»ï¼Œè‡ªåŠ¨é‡è¯•æ›´å¤§èŒƒå›´
  ğŸš€ å¤šç­–ç•¥æœç´¢: ğŸ†• æ ‡å‡† â†’ æ‰©å¤§ â†’ å…¨å›¾ â†’ æ¨¡æ¿åŒ¹é…
  ğŸš€ é‡å¤è¿‡æ»¤: æ™ºèƒ½æ£€æµ‹å¹¶ç§»é™¤é‡å¤å›¾ç‰‡
  ğŸš€ ç‰¹å¾ç‚¹æ•°é‡: 1500 â†’ 2000
  ğŸš€ çº¹ç†æ£€æµ‹: è‡ªåŠ¨è¯†åˆ«ä½çº¹ç†åŒºåŸŸ
  ğŸš€ è¾¹ç¼˜å¢å¼º: ä½çº¹ç†æ—¶ä½¿ç”¨ç›´æ–¹å›¾å‡è¡¡åŒ–
  ğŸš€ Xè½´çº¦æŸ: è¿‡æ»¤ä¸ç¬¦åˆå‚ç›´æ‹¼æ¥çš„åŒ¹é…ç‚¹
  ğŸš€ MADå¼‚å¸¸å€¼æ£€æµ‹: æ¯”å››åˆ†ä½æ•°æ›´é²æ£’
  ğŸš€ ç©ºé—´åˆ†å¸ƒæ£€æŸ¥: é¿å…ç‰¹å¾ç‚¹èšé›†
  ğŸš€ ç½®ä¿¡åº¦6ç»´åº¦: æ›´å…¨é¢çš„è´¨é‡è¯„ä¼°
  ğŸš€ å¤šå±‚é™çº§: ç‰¹å¾ç‚¹ â†’ æ¨¡æ¿åŒ¹é… â†’ ç®€å•æ‹¼æ¥
  ğŸš€ ä¸¤ä¸¤é…å¯¹: å‡å°‘ç´¯ç§¯è¯¯å·®ï¼ŒåŒ¹é…æ›´å‡†ç¡®

ç½®ä¿¡åº¦è®¡ç®—:
  - åŒ¹é…æ•°é‡ (25%): 50ä¸ªåŒ¹é…ç‚¹æ»¡åˆ†
  - ç¨³å®šæ€§ (25%): æ ‡å‡†å·®è¶Šå°è¶Šå¥½
  - åŒ¹é…è·ç¦» (15%): ç‰¹å¾æè¿°ç¬¦è·ç¦»
  - å†…ç‚¹æ¯”ä¾‹ (15%): RANSACå†…ç‚¹æ¯”ä¾‹
  - Xè½´çº¦æŸ (10%): Xè½´åç§»åº”æ¥è¿‘0
  - ç©ºé—´åˆ†å¸ƒ (10%): åŒ¹é…ç‚¹åº”å‡åŒ€åˆ†å¸ƒ

é€‚ç”¨åœºæ™¯:
  ğŸ“± ç½‘é¡µé•¿æˆªå›¾ - å¤„ç†åŠ¨æ€å¹¿å‘Šã€è‡ªåŠ¨è¿‡æ»¤é‡å¤å¸§
  ğŸ’¬ èŠå¤©è®°å½• - ç²¾ç¡®å¯¹é½æ–‡å­—
  ğŸ“„ æ–‡æ¡£æ‹¼æ¥ - æ— ç¼æ‹¼æ¥
  ğŸ¨ ä½çº¹ç†å›¾åƒ - çº¯è‰²ã€æ¸å˜èƒŒæ™¯
"""

import cv2
import numpy as np
from PIL import Image
from typing import List, Union, Tuple, Optional
from pathlib import Path


def pil_to_cv2(pil_image: Image.Image) -> np.ndarray:
    """å°†PIL Imageè½¬æ¢ä¸ºOpenCVæ ¼å¼"""
    if pil_image.mode == 'RGB':
        return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    elif pil_image.mode == 'RGBA':
        return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGBA2BGRA)
    else:
        return np.array(pil_image.convert('RGB'))


def cv2_to_pil(cv2_image: np.ndarray) -> Image.Image:
    """å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPIL Image"""
    if len(cv2_image.shape) == 2:  # ç°åº¦å›¾
        return Image.fromarray(cv2_image)
    elif cv2_image.shape[2] == 3:  # BGR
        return Image.fromarray(cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB))
    elif cv2_image.shape[2] == 4:  # BGRA
        return Image.fromarray(cv2.cvtColor(cv2_image, cv2.COLOR_BGRA2RGBA))
    else:
        return Image.fromarray(cv2_image)


def _detect_texture_level(gray_image: np.ndarray) -> float:
    """
    æ£€æµ‹å›¾åƒçº¹ç†ä¸°å¯Œåº¦
    
    Args:
        gray_image: ç°åº¦å›¾åƒ
        
    Returns:
        çº¹ç†åˆ†æ•° 0.0-1.0 (è¶Šé«˜è¶Šä¸°å¯Œ)
    """
    # ä½¿ç”¨Laplacianæ–¹å·®è¯„ä¼°çº¹ç†
    laplacian = cv2.Laplacian(gray_image, cv2.CV_64F)
    variance = laplacian.var()
    
    # å½’ä¸€åŒ–åˆ°0-1
    texture_score = min(variance / 1000.0, 1.0)
    
    return texture_score


def _adaptive_feature_detection(gray1: np.ndarray, gray2: np.ndarray,
                                base_nfeatures: int = 2000) -> Tuple:
    """
    è‡ªé€‚åº”ç‰¹å¾æ£€æµ‹ - æ ¹æ®çº¹ç†ä¸°å¯Œåº¦è°ƒæ•´æ£€æµ‹ç­–ç•¥
    
    Args:
        gray1, gray2: ç°åº¦å›¾åƒ
        base_nfeatures: åŸºç¡€ç‰¹å¾ç‚¹æ•°é‡
        
    Returns:
        (kp1, des1, kp2, des2, method_used)
    """
    # æ£€æµ‹çº¹ç†æ°´å¹³
    texture1 = _detect_texture_level(gray1)
    texture2 = _detect_texture_level(gray2)
    avg_texture = (texture1 + texture2) / 2
    
    print(f"   çº¹ç†ä¸°å¯Œåº¦: img1={texture1:.3f}, img2={texture2:.3f}, avg={avg_texture:.3f}")
    
    # æ ¹æ®çº¹ç†ä¸°å¯Œåº¦è°ƒæ•´ç­–ç•¥
    if avg_texture > 0.3:
        # çº¹ç†ä¸°å¯Œ - ä½¿ç”¨æ ‡å‡†ORB
        print(f"   ä½¿ç”¨æ ‡å‡†ORBæ£€æµ‹å™¨")
        orb = cv2.ORB_create(
            nfeatures=base_nfeatures,
            scaleFactor=1.2,
            nlevels=8,
            edgeThreshold=10,
            firstLevel=0,
            WTA_K=2,
            scoreType=cv2.ORB_HARRIS_SCORE,
            patchSize=31,
            fastThreshold=15
        )
        kp1, des1 = orb.detectAndCompute(gray1, None)
        kp2, des2 = orb.detectAndCompute(gray2, None)
        return kp1, des1, kp2, des2, "ORB"
        
    else:
        # çº¹ç†ç¨€ç– - ä½¿ç”¨æ›´æ•æ„Ÿçš„æ£€æµ‹å™¨ + è¾¹ç¼˜å¢å¼º
        print(f"   çº¹ç†ç¨€ç–,ä½¿ç”¨å¢å¼ºORB + è¾¹ç¼˜å¢å¼º")
        
        # è¾¹ç¼˜å¢å¼º
        gray1_enhanced = cv2.equalizeHist(gray1)
        gray2_enhanced = cv2.equalizeHist(gray2)
        
        # æ›´æ•æ„Ÿçš„ORBè®¾ç½®
        orb = cv2.ORB_create(
            nfeatures=int(base_nfeatures * 1.5),  # å¢åŠ ç‰¹å¾ç‚¹
            scaleFactor=1.15,  # æ›´ç»†çš„å°ºåº¦
            nlevels=10,        # æ›´å¤šå°ºåº¦å±‚çº§
            edgeThreshold=5,   # æ›´ä½çš„è¾¹ç¼˜é˜ˆå€¼
            firstLevel=0,
            WTA_K=2,
            scoreType=cv2.ORB_HARRIS_SCORE,
            patchSize=31,
            fastThreshold=10   # æ›´æ•æ„Ÿçš„FASTé˜ˆå€¼
        )
        
        kp1, des1 = orb.detectAndCompute(gray1_enhanced, None)
        kp2, des2 = orb.detectAndCompute(gray2_enhanced, None)
        
        return kp1, des1, kp2, des2, "ORB-Enhanced"


def _template_matching_fallback(img1: np.ndarray, img2: np.ndarray,
                                overlap_ratio: float = 0.3) -> Tuple[Optional[int], float]:
    """
    æ¨¡æ¿åŒ¹é…åå¤‡æ–¹æ¡ˆ - ç”¨äºç‰¹å¾ç‚¹åŒ¹é…å®Œå…¨å¤±è´¥æ—¶
    
    Args:
        img1: ç¬¬ä¸€å¼ å›¾ç‰‡
        img2: ç¬¬äºŒå¼ å›¾ç‰‡
        overlap_ratio: é¢„ä¼°é‡å æ¯”ä¾‹
        
    Returns:
        (offset_y, confidence)
    """
    try:
        print(f"   ğŸ”„ å¯ç”¨æ¨¡æ¿åŒ¹é…åå¤‡æ–¹æ¡ˆ")
        
        h1, w1 = img1.shape[:2]
        h2, w2 = img2.shape[:2]
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(img1.shape) == 3:
            gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
        else:
            gray1 = img1
            gray2 = img2
        
        # é¢„ä¼°é‡å åŒºåŸŸ
        overlap_height = int(min(h1, h2) * overlap_ratio)
        if overlap_height < 50:
            overlap_height = min(100, min(h1, h2) // 2)
        
        # ä»img2é¡¶éƒ¨å–æ¨¡æ¿
        template = gray2[:overlap_height, :]
        
        # åœ¨img1åº•éƒ¨æœç´¢
        search_height = int(h1 * 0.6)  # åœ¨åº•éƒ¨60%æœç´¢
        search_region = gray1[-search_height:, :]
        
        # æ¨¡æ¿åŒ¹é…
        result = cv2.matchTemplate(search_region, template, cv2.TM_CCOEFF_NORMED)
        _, max_val, _, max_loc = cv2.minMaxLoc(result)
        
        # è®¡ç®—offset_y
        match_y_in_search = max_loc[1]
        search_start = h1 - search_height
        offset_y = search_start + match_y_in_search
        
        # ç½®ä¿¡åº¦ = åŒ¹é…åˆ†æ•°
        confidence = float(max_val) * 0.7  # é™æƒ,å› ä¸ºæ˜¯åå¤‡æ–¹æ¡ˆ
        
        print(f"   æ¨¡æ¿åŒ¹é…: offset_y={offset_y}, confidence={confidence:.3f}, score={max_val:.3f}")
        
        return offset_y, confidence
        
    except Exception as e:
        print(f"   âŒ æ¨¡æ¿åŒ¹é…å¤±è´¥: {e}")
        return None, 0.0




def find_overlap_region(img1: np.ndarray, img2: np.ndarray, 
                       overlap_ratio: float = 0.3,
                       min_match_count: int = 10,
                       use_multi_scale: bool = True,
                       scroll_distance: int = None) -> Tuple[Optional[int], float]:
    """
    ä½¿ç”¨ORBç‰¹å¾ç‚¹åŒ¹é…æ‰¾åˆ°ä¸¤å¼ å›¾ç‰‡çš„é‡å åŒºåŸŸï¼ˆæ”¯æŒæ»šåŠ¨è·ç¦»è¾…åŠ©ï¼‰
    
    ä¼˜åŒ–ç‰ˆæœ¬ (2025-11-13 æ··åˆæ–¹æ¡ˆå‡çº§):
    - ğŸ†• æ»šåŠ¨è·ç¦»è¾…åŠ©ï¼šä½¿ç”¨ç‰©ç†æ»šåŠ¨è·ç¦»ç¼©å°æœç´¢èŒƒå›´ï¼Œæé«˜å‡†ç¡®æ€§
    - ğŸ†• Yè½´å‡ ä½•çº¦æŸéªŒè¯ (Yåç§»ä¸åº”ä¸ºè´Ÿæ•°)
    - ğŸ†• å¼‚å¸¸æ£€æµ‹ + è‡ªåŠ¨é‡è¯•æœºåˆ¶ (æ‰©å¤§æœç´¢åŒºåŸŸ)
    - å¤šå°ºåº¦ç‰¹å¾æ£€æµ‹(æé«˜é²æ£’æ€§)
    - å‡ ä½•çº¦æŸ(Xè½´åç§»åº”æ¥è¿‘0)
    - æ”¹è¿›çš„RANSACå¼‚å¸¸å€¼è¿‡æ»¤
    - åŒ¹é…ç‚¹ç©ºé—´åˆ†å¸ƒæ£€æŸ¥
    
    Args:
        img1: ç¬¬ä¸€å¼ å›¾ç‰‡ï¼ˆä¸Šé¢çš„ï¼‰
        img2: ç¬¬äºŒå¼ å›¾ç‰‡ï¼ˆä¸‹é¢çš„ï¼‰
        overlap_ratio: æœç´¢èŒƒå›´æ¯”ä¾‹ï¼ˆä¸æ˜¯é¢„ä¼°é‡å ï¼Œè€Œæ˜¯æœç´¢åŒºåŸŸå¤§å°ï¼‰
        min_match_count: æœ€å°åŒ¹é…ç‚¹æ•°é‡
        use_multi_scale: æ˜¯å¦ä½¿ç”¨å¤šå°ºåº¦æ£€æµ‹
        scroll_distance: ğŸ†• æ»šåŠ¨è·ç¦»ï¼ˆåƒç´ ï¼‰ï¼Œç”¨äºç¼©å°æœç´¢èŒƒå›´
        
    Returns:
        (offset_y, confidence): Yè½´åç§»é‡å’Œç½®ä¿¡åº¦
    """
    # ğŸ†• æ ¹æ®æ˜¯å¦æœ‰æ»šåŠ¨è·ç¦»ä¿¡æ¯é€‰æ‹©æœç´¢ç­–ç•¥
    if scroll_distance is not None and scroll_distance > 0:
        # æœ‰æ»šåŠ¨è·ç¦»ä¿¡æ¯ï¼šä½¿ç”¨ç²¾ç¡®æœç´¢
        h1 = img1.shape[0]
        
        # ğŸ”§ æ»šåŠ¨è·ç¦»æ ¡å‡†ï¼šå®é™…å›¾åƒåç§»é€šå¸¸å°äºç†è®ºæ»šåŠ¨è·ç¦»
        # æ ¹æ®ç»éªŒï¼Œå®é™…åç§»çº¦ä¸ºæ»šåŠ¨è·ç¦»çš„50-70%
        scroll_efficiency = 0.6  # å¯ä»¥æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´
        estimated_offset = int(scroll_distance * scroll_efficiency)
        
        print(f"ğŸ“ ä½¿ç”¨æ»šåŠ¨è·ç¦»è¾…åŠ©: {scroll_distance}px â†’ ä¼°ç®—offset={estimated_offset} (æ ¡å‡†åï¼Œæ•ˆç‡={scroll_efficiency})")
        print(f"   é€»è¾‘: æ»šåŠ¨{scroll_distance}px Ã— {scroll_efficiency} = img2é¡¶éƒ¨å¯¹åº”img1ç¬¬{estimated_offset}pxä½ç½®")
        
        strategies = [
            {'name': 'ç²¾ç¡®æœç´¢(Â±15px)', 'search_ratio_multiplier': 2.0, 'use_full_height': False, 
             'centered_search': True, 'center_offset': estimated_offset, 'search_range': 15},
            {'name': 'æ‰©å¤§æœç´¢(Â±30px)', 'search_ratio_multiplier': 2.0, 'use_full_height': False,
             'centered_search': True, 'center_offset': estimated_offset, 'search_range': 30},
            {'name': 'åå¤‡æœç´¢(Â±60px)', 'search_ratio_multiplier': 2.0, 'use_full_height': False,
             'centered_search': True, 'center_offset': estimated_offset, 'search_range': 60},
        ]
    else:
        # æ— æ»šåŠ¨è·ç¦»ï¼šä½¿ç”¨ä¼ ç»Ÿå¤§èŒƒå›´æœç´¢
        strategies = [
            {'name': 'æ ‡å‡†ç­–ç•¥', 'search_ratio_multiplier': 2.0, 'use_full_height': False},
            {'name': 'æ‰©å¤§æœç´¢', 'search_ratio_multiplier': 3.0, 'use_full_height': False},
            {'name': 'å…¨å›¾æœç´¢', 'search_ratio_multiplier': 1.0, 'use_full_height': True},
        ]
    
    for strategy_idx, strategy in enumerate(strategies):
        try:
            result = _try_find_overlap(
                img1, img2, overlap_ratio, min_match_count, 
                strategy, strategy_idx
            )
            
            if result is not None:
                offset_y, confidence, y_median_offset = result
                
                # ğŸ†• éªŒè¯Yåç§»åˆç†æ€§ (ä¸åº”ä¸ºè´Ÿæ•°ï¼Œé™¤éè¯¯å·®å¾ˆå°)
                if y_median_offset < -10:
                    print(f"   âš ï¸ Yåç§»å¼‚å¸¸ (median={y_median_offset:.1f}px < -10px)ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç­–ç•¥...")
                    if strategy_idx < len(strategies) - 1:
                        continue  # å°è¯•ä¸‹ä¸€ä¸ªç­–ç•¥
                    else:
                        print(f"   âš ï¸ æ‰€æœ‰ç­–ç•¥å‡å¤±è´¥ï¼Œé™çº§åˆ°æ¨¡æ¿åŒ¹é…")
                        return _template_matching_fallback(img1, img2, overlap_ratio)
                
                # Yåç§»åˆç†ï¼Œè¿”å›ç»“æœ
                return offset_y, confidence
            
            # å½“å‰ç­–ç•¥å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ª
            if strategy_idx < len(strategies) - 1:
                print(f"   âš ï¸ {strategy['name']}å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç­–ç•¥...")
                continue
        
        except Exception as e:
            print(f"   âŒ {strategy['name']}å‡ºé”™: {e}")
            if strategy_idx < len(strategies) - 1:
                continue
    
    # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿åŒ¹é…
    print(f"   âš ï¸ æ‰€æœ‰ç‰¹å¾åŒ¹é…ç­–ç•¥å¤±è´¥ï¼Œé™çº§åˆ°æ¨¡æ¿åŒ¹é…")
    return _template_matching_fallback(img1, img2, overlap_ratio)


def _try_find_overlap(img1: np.ndarray, img2: np.ndarray,
                     overlap_ratio: float,
                     min_match_count: int,
                     strategy: dict,
                     strategy_idx: int) -> Optional[Tuple[int, float, float]]:
    """
    å°è¯•ä½¿ç”¨æŒ‡å®šç­–ç•¥æŸ¥æ‰¾é‡å åŒºåŸŸ
    
    Returns:
        (offset_y, confidence, y_median_offset) æˆ– None
    """
    try:
        h1, w1 = img1.shape[:2]
        h2, w2 = img2.shape[:2]
        
        if strategy_idx == 0:
            print(f"\nğŸ” ç‰¹å¾ç‚¹åŒ¹é…: img1={h1}x{w1}, img2={h2}x{w2}")
        print(f"   ç­–ç•¥: {strategy['name']}")
        
        # ğŸ†• 1. æ ¹æ®ç­–ç•¥æå–æœç´¢åŒºåŸŸï¼ˆæ”¯æŒcentered_searchï¼‰
        if strategy.get('centered_search', False):
            # ç²¾ç¡®æœç´¢æ¨¡å¼ï¼šåœ¨ä¼°ç®—ä½ç½®é™„è¿‘æœç´¢é‡å åŒºåŸŸ
            center_offset = strategy['center_offset']
            search_range = strategy['search_range']
            
            # ğŸ”§ ä¿®æ­£æœç´¢åŒºåŸŸé€»è¾‘ï¼šæœç´¢é‡å åŒºåŸŸï¼Œè€Œä¸æ˜¯ä»»æ„åŒºåŸŸ
            # offset=155px æ„å‘³ç€ img2é¡¶éƒ¨å¯¹åº”img1ç¬¬155pxä½ç½®
            # é‡å åŒºåŸŸæ˜¯ï¼šimg1[155:518] å¯¹åº” img2[0:363]
            
            # img1æœç´¢åŒºåŸŸï¼šä»offsetå¼€å§‹ï¼Œå…è®¸Â±search_rangeçš„è¯¯å·®
            region1_start = max(0, center_offset - search_range)
            region1_end = min(h1, h1)  # æœç´¢åˆ°img1åº•éƒ¨
            
            # img2æœç´¢åŒºåŸŸï¼šä»é¡¶éƒ¨å¼€å§‹ï¼Œé«˜åº¦å¯¹åº”é‡å åŒºåŸŸ
            overlap_height = h1 - center_offset + search_range
            region2_end = min(h2, overlap_height)
            
            region1 = img1[region1_start:region1_end, :]
            region2 = img2[0:region2_end, :]
            
            print(f"   ğŸ¯ ä¸­å¿ƒæœç´¢: offset={center_offset}px, èŒƒå›´=Â±{search_range}px")
            print(f"   æœç´¢åŒºåŸŸ: region1=[{region1_start}:{region1_end}], region2=[0:{region2_end}]")
            print(f"   é€»è¾‘: img1[{center_offset}:] åº”è¯¥åŒ¹é… img2[0:], å…è®¸Â±{search_range}pxè¯¯å·®")
            
        elif strategy['use_full_height']:
            # å…¨å›¾æœç´¢
            region1 = img1
            region2 = img2
            region1_start = 0
        else:
            # éƒ¨åˆ†æœç´¢ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰
            search_ratio = max(0.5, overlap_ratio * strategy['search_ratio_multiplier'])
            search_height1 = int(h1 * search_ratio)
            search_height2 = int(h2 * search_ratio)
            
            region1 = img1[-search_height1:, :]  # img1çš„ä¸‹åŠéƒ¨åˆ†
            region2 = img2[:search_height2, :]   # img2çš„ä¸ŠåŠéƒ¨åˆ†
            region1_start = h1 - search_height1
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(region1.shape) == 3:
            gray1 = cv2.cvtColor(region1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(region2, cv2.COLOR_BGR2GRAY)
        else:
            gray1 = region1
            gray2 = region2
        
        print(f"   æœç´¢åŒºåŸŸ: region1={gray1.shape}, region2={gray2.shape}")
        
        # 2. è‡ªé€‚åº”ç‰¹å¾æ£€æµ‹(æ ¹æ®çº¹ç†ä¸°å¯Œåº¦é€‰æ‹©ç­–ç•¥)
        kp1, des1, kp2, des2, method = _adaptive_feature_detection(
            gray1, gray2, base_nfeatures=2000
        )
        
        if des1 is None or des2 is None or len(kp1) < min_match_count:
            print(f"   âŒ ç‰¹å¾ç‚¹ä¸è¶³: img1={len(kp1) if kp1 else 0}, img2={len(kp2) if kp2 else 0}")
            return None
        
        print(f"   ç‰¹å¾ç‚¹({method}): img1={len(kp1)}, img2={len(kp2)}")
        
        # 3. ç‰¹å¾åŒ¹é…ï¼ˆBFMatcherï¼‰
        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)
        
        try:
            matches = bf.knnMatch(des1, des2, k=2)
        except cv2.error as e:
            print(f"   âŒ åŒ¹é…å¤±è´¥: {e}")
            return None
        
        # 4. Lowe's ratio test ç­›é€‰å¥½çš„åŒ¹é…
        good_matches = []
        for match_pair in matches:
            if len(match_pair) == 2:
                m, n = match_pair
                if m.distance < 0.75 * n.distance:  # Loweæ¨èçš„é˜ˆå€¼
                    good_matches.append(m)
        
        print(f"   åŒ¹é…: æ€»æ•°={len(matches)}, ä¼˜è´¨={len(good_matches)}")
        
        if len(good_matches) < min_match_count:
            print(f"   âš ï¸ ä¼˜è´¨åŒ¹é…è¿‡å°‘ ({len(good_matches)} < {min_match_count})")
            return None
        
        # 5. æå–åŒ¹é…ç‚¹åæ ‡
        pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])
        pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])
        
        # ğŸ†• 6. å‡ ä½•çº¦æŸéªŒè¯ - å‚ç›´æ‹¼æ¥æ—¶Xè½´åç§»åº”æ¥è¿‘0
        x_offsets = pts1[:, 0] - pts2[:, 0]
        x_median = np.median(x_offsets)
        x_std = np.std(x_offsets)
        
        # è¿‡æ»¤Xè½´åç§»å¼‚å¸¸çš„ç‚¹(è¶…è¿‡3å€æ ‡å‡†å·®)
        x_inliers_mask = np.abs(x_offsets - x_median) < 3 * max(x_std, 5)
        
        if np.sum(x_inliers_mask) < min_match_count:
            print(f"   âš ï¸ Xè½´çº¦æŸè¿‡æ»¤ååŒ¹é…ç‚¹ä¸è¶³: {np.sum(x_inliers_mask)}")
            x_penalty = 0.5
        else:
            # åº”ç”¨Xè½´è¿‡æ»¤
            pts1 = pts1[x_inliers_mask]
            pts2 = pts2[x_inliers_mask]
            good_matches = [m for i, m in enumerate(good_matches) if x_inliers_mask[i]]
            x_penalty = 1.0
            print(f"   âœ… Xè½´çº¦æŸè¿‡æ»¤: ä¿ç•™ {len(good_matches)} ä¸ªåŒ¹é…ç‚¹ (X_median={x_median:.1f}px, X_std={x_std:.1f}px)")
        
        # ğŸ†• 7. æ”¹è¿›çš„Yè½´åç§»è®¡ç®— - ä½¿ç”¨RANSACæ€æƒ³
        y_offsets = pts1[:, 1] - pts2[:, 1]
        
        # ä½¿ç”¨æ”¹è¿›çš„å¼‚å¸¸å€¼è¿‡æ»¤(MAD - Median Absolute Deviation)
        if len(y_offsets) >= 4:
            y_median = np.median(y_offsets)
            mad = np.median(np.abs(y_offsets - y_median))
            
            # MAD-based å¼‚å¸¸å€¼æ£€æµ‹(æ›´é²æ£’)
            if mad > 0:
                modified_z_scores = 0.6745 * (y_offsets - y_median) / mad
                y_inliers_mask = np.abs(modified_z_scores) < 3.5
            else:
                # MADä¸º0è¯´æ˜æ‰€æœ‰ç‚¹å‡ ä¹ä¸€è‡´,ç›´æ¥ä½¿ç”¨
                y_inliers_mask = np.ones(len(y_offsets), dtype=bool)
            
            if np.sum(y_inliers_mask) >= 3:
                y_filtered = y_offsets[y_inliers_mask]
                median_offset = np.median(y_filtered)
                std_offset = np.std(y_filtered)
                inlier_ratio = np.sum(y_inliers_mask) / len(y_offsets)
                print(f"   Yè½´RANSAC: å†…ç‚¹æ¯”ä¾‹={inlier_ratio:.1%}, æœ‰æ•ˆç‚¹={np.sum(y_inliers_mask)}/{len(y_offsets)}")
            else:
                # RANSACå¤±è´¥,å›é€€åˆ°å››åˆ†ä½æ•°
                y_sorted = np.sort(y_offsets)
                q1_idx = len(y_sorted) // 4
                q3_idx = 3 * len(y_sorted) // 4
                y_filtered = y_sorted[q1_idx:q3_idx]
                median_offset = np.median(y_filtered)
                std_offset = np.std(y_filtered)
                inlier_ratio = 0.5
                print(f"   Yè½´å››åˆ†ä½: ä½¿ç”¨ä¸­é—´50%çš„ç‚¹")
        else:
            median_offset = np.median(y_offsets)
            std_offset = np.std(y_offsets)
            inlier_ratio = 1.0
        
        print(f"   Yè½´åç§»: median={median_offset:.1f}px, std={std_offset:.1f}px")
        
        # ğŸ†• 8. è®¡ç®—å®é™…offset_yï¼ˆä»img1é¡¶éƒ¨ç®—èµ·ï¼‰
        offset_y = int(region1_start + median_offset)
        
        # ğŸ†• 9. æ”¹è¿›çš„ç½®ä¿¡åº¦è®¡ç®—ï¼ˆå¤šç»´åº¦ç»¼åˆè¯„ä¼°ï¼‰
        # 9.1 åŒ¹é…æ•°é‡ç½®ä¿¡åº¦
        num_confidence = min(len(good_matches) / 50.0, 1.0)
        
        # 9.2 ç¨³å®šæ€§ç½®ä¿¡åº¦(æ ‡å‡†å·®)
        std_confidence = max(0, 1.0 - std_offset / 50.0)
        
        # 9.3 åŒ¹é…è·ç¦»ç½®ä¿¡åº¦
        avg_distance = np.mean([m.distance for m in good_matches])
        dist_confidence = max(0, 1.0 - avg_distance / 100.0)
        
        # ğŸ†• 9.4 å†…ç‚¹æ¯”ä¾‹ç½®ä¿¡åº¦
        inlier_confidence = inlier_ratio
        
        # ğŸ†• 9.5 Xè½´çº¦æŸç½®ä¿¡åº¦
        x_constraint_confidence = 1.0 if abs(x_median) < 10 and x_std < 5 else max(0, 1.0 - abs(x_median) / 50.0)
        
        # ğŸ†• 9.6 ç©ºé—´åˆ†å¸ƒç½®ä¿¡åº¦(åŒ¹é…ç‚¹åº”å‡åŒ€åˆ†å¸ƒ,é¿å…èšé›†)
        if len(good_matches) >= 10:
            pts1_y = pts1[:, 1]
            y_range = np.max(pts1_y) - np.min(pts1_y)
            y_coverage = y_range / gray1.shape[0] if gray1.shape[0] > 0 else 0
            spatial_confidence = min(y_coverage / 0.3, 1.0)  # æœŸæœ›è¦†ç›–è‡³å°‘30%çš„åŒºåŸŸ
        else:
            spatial_confidence = 0.5
        
        # ç»¼åˆç½®ä¿¡åº¦(åŠ æƒå¹³å‡)
        confidence = (
            num_confidence * 0.25 +          # åŒ¹é…æ•°é‡ 25%
            std_confidence * 0.25 +          # ç¨³å®šæ€§ 25%
            dist_confidence * 0.15 +         # è·ç¦» 15%
            inlier_confidence * 0.15 +       # å†…ç‚¹æ¯”ä¾‹ 15%
            x_constraint_confidence * 0.10 + # Xè½´çº¦æŸ 10%
            spatial_confidence * 0.10        # ç©ºé—´åˆ†å¸ƒ 10%
        )
        
        confidence *= x_penalty  # åº”ç”¨Xè½´çº¦æŸæƒ©ç½š
        
        print(f"   ç½®ä¿¡åº¦: {confidence:.3f}")
        print(f"      åŒ¹é…={num_confidence:.2f}, ç¨³å®š={std_confidence:.2f}, è·ç¦»={dist_confidence:.2f}")
        print(f"      å†…ç‚¹={inlier_confidence:.2f}, Xçº¦æŸ={x_constraint_confidence:.2f}, åˆ†å¸ƒ={spatial_confidence:.2f}")
        
        # ğŸ†• æ»šåŠ¨è·ç¦»æ ¡å‡†åé¦ˆï¼ˆå¦‚æœæœ‰æ»šåŠ¨è·ç¦»ä¿¡æ¯ï¼‰
        if strategy.get('centered_search', False) and 'center_offset' in strategy:
            expected_offset = strategy['center_offset']
            actual_offset = offset_y
            offset_error = abs(actual_offset - expected_offset)
            
            print(f"   ğŸ“Š æ»šåŠ¨æ ¡å‡†: é¢„æœŸoffset={expected_offset}px, å®é™…={actual_offset}px, è¯¯å·®={offset_error}px")
            
            if offset_error <= 30:
                print(f"   âœ… æ»šåŠ¨æ ¡å‡†è‰¯å¥½: è¯¯å·®åœ¨Â±30pxèŒƒå›´å†…")
            elif offset_error <= 60:
                print(f"   âš ï¸ æ»šåŠ¨æ ¡å‡†åå·®: è¯¯å·®{offset_error}px, å»ºè®®è°ƒæ•´æ»šåŠ¨æ•ˆç‡")
            else:
                print(f"   âŒ æ»šåŠ¨æ ¡å‡†å¤±æ•ˆ: è¯¯å·®{offset_error}pxè¿‡å¤§")
        
        # 10. éªŒè¯åˆç†æ€§ï¼ˆæ”¹è¿›çš„é€»è¾‘ï¼‰
        overlap_height = h1 - offset_y
        
        # 10.1 åŸºæœ¬åˆç†æ€§æ£€æŸ¥
        if overlap_height <= 0:
            print(f"   âŒ æ— é‡å  (overlap={overlap_height}px)")
            confidence *= 0.2
            return offset_y, confidence, median_offset
        
        if overlap_height >= h2:
            # ç‰¹æ®Šæƒ…å†µï¼šimg2å®Œå…¨åœ¨img1èŒƒå›´å†…ï¼ˆæœ€åä¸€æ¬¡å¾ˆå°çš„æ»šåŠ¨ï¼‰
            # è¿™æ˜¯åˆç†çš„ï¼è®¡ç®—çœŸå®çš„é‡å æ¯”ä¾‹
            overlap_ratio_to_img2 = overlap_height / h2
            
            if overlap_ratio_to_img2 > 1.0:
                # img2å®Œå…¨åŒ…å«åœ¨é‡å åŒºåŸŸå†…
                actual_new_height = offset_y + h2
                
                # æ£€æŸ¥ç‰¹å¾åŒ¹é…çš„è´¨é‡
                if len(good_matches) >= 50 and std_offset < 10:
                    # ç‰¹å¾åŒ¹é…è´¨é‡å¾ˆå¥½ï¼Œç›¸ä¿¡è¿™ä¸ªç»“æœ
                    print(f"   âœ… å°æ»šåŠ¨æ£€æµ‹: offset_y={offset_y}, img2å®Œå…¨åœ¨é‡å åŒºåŸŸå†…")
                    print(f"      img2é«˜åº¦={h2}px, é‡å ={overlap_height}px, æ–°å¢={h2-overlap_height}px")
                    # ä¸æƒ©ç½šç½®ä¿¡åº¦
                    return offset_y, confidence, median_offset
                else:
                    print(f"   âš ï¸ é‡å å¼‚å¸¸: {overlap_height}px >= img2é«˜åº¦ {h2}pxï¼Œä¸”åŒ¹é…è´¨é‡ä¸è¶³")
                    confidence *= 0.3
                    return offset_y, confidence, median_offset
        
        # 10.2 æ­£å¸¸æƒ…å†µï¼šè®¡ç®—é‡å æ¯”ä¾‹
        # ä½¿ç”¨img2é«˜åº¦ä½œä¸ºåŸºå‡†ï¼ˆæ›´åˆç†ï¼‰
        overlap_ratio_to_img2 = overlap_height / h2
        
        if overlap_ratio_to_img2 < 0.05:
            # é‡å å¤ªå°‘ï¼ˆ<5%ï¼‰
            print(f"   âš ï¸ é‡å è¿‡å°‘: {overlap_height}px ({overlap_ratio_to_img2:.1%})")
            confidence *= 0.7  # è½»å¾®æƒ©ç½š
        elif overlap_ratio_to_img2 > 0.95:
            # é‡å å¾ˆå¤§ï¼ˆ>95%ï¼‰ï¼Œä½†å¦‚æœç‰¹å¾åŒ¹é…å¥½ï¼Œå¯èƒ½æ˜¯å°æ»šåŠ¨
            if len(good_matches) >= 30 and std_offset < 5:
                print(f"   âœ… å°æ»šåŠ¨: offset_y={offset_y}, é‡å ={overlap_height}px ({overlap_ratio_to_img2:.1%})")
                # ä¸æƒ©ç½š
            else:
                print(f"   âš ï¸ é‡å è¿‡å¤§: {overlap_height}px ({overlap_ratio_to_img2:.1%})")
                confidence *= 0.6
        else:
            # æ­£å¸¸èŒƒå›´ï¼ˆ5%-95%ï¼‰
            print(f"   âœ… é‡å åˆç†: offset_y={offset_y}, é«˜åº¦={overlap_height}px ({overlap_ratio_to_img2:.1%})")
        
        return offset_y, confidence, median_offset
        
    except Exception as e:
        print(f"   âŒ ç‰¹å¾åŒ¹é…å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None

        
        if strategy_idx == 0:
            print(f"\nğŸ” ç‰¹å¾ç‚¹åŒ¹é…: img1={h1}x{w1}, img2={h2}x{w2}")
        print(f"   ç­–ç•¥: {strategy['name']}")
        
        # 1. æ ¹æ®ç­–ç•¥æå–æœç´¢åŒºåŸŸ
        if strategy['use_full_height']:
            # å…¨å›¾æœç´¢
            region1 = img1
            region2 = img2
            region1_start = 0
        else:
            # éƒ¨åˆ†æœç´¢
            search_ratio = max(0.5, overlap_ratio * strategy['search_ratio_multiplier'])
            search_height1 = int(h1 * search_ratio)
            search_height2 = int(h2 * search_ratio)
            
            region1 = img1[-search_height1:, :]  # img1çš„ä¸‹åŠéƒ¨åˆ†
            region2 = img2[:search_height2, :]   # img2çš„ä¸ŠåŠéƒ¨åˆ†
            region1_start = h1 - search_height1
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(region1.shape) == 3:
            gray1 = cv2.cvtColor(region1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(region2, cv2.COLOR_BGR2GRAY)
        else:
            gray1 = region1
            gray2 = region2
        
        print(f"   æœç´¢åŒºåŸŸ: region1={gray1.shape}, region2={gray2.shape}")
        
        # 2. è‡ªé€‚åº”ç‰¹å¾æ£€æµ‹(æ ¹æ®çº¹ç†ä¸°å¯Œåº¦é€‰æ‹©ç­–ç•¥)
        kp1, des1, kp2, des2, method = _adaptive_feature_detection(
            gray1, gray2, base_nfeatures=2000
        )
        
        if des1 is None or des2 is None or len(kp1) < min_match_count:
            print(f"   âŒ ç‰¹å¾ç‚¹ä¸è¶³: img1={len(kp1) if kp1 else 0}, img2={len(kp2) if kp2 else 0}")
            # ğŸ†• å°è¯•æ¨¡æ¿åŒ¹é…ä½œä¸ºåå¤‡
            return _template_matching_fallback(img1, img2, overlap_ratio)
        
        print(f"   ç‰¹å¾ç‚¹({method}): img1={len(kp1)}, img2={len(kp2)}")
        
        # 3. ç‰¹å¾åŒ¹é…ï¼ˆBFMatcherï¼‰
        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)
        
        try:
            matches = bf.knnMatch(des1, des2, k=2)
        except cv2.error as e:
            print(f"   âŒ åŒ¹é…å¤±è´¥: {e}")
            return None, 0.0
        
        # 4. Lowe's ratio test ç­›é€‰å¥½çš„åŒ¹é…
        good_matches = []
        for match_pair in matches:
            if len(match_pair) == 2:
                m, n = match_pair
                if m.distance < 0.75 * n.distance:  # Loweæ¨èçš„é˜ˆå€¼
                    good_matches.append(m)
        
        print(f"   åŒ¹é…: æ€»æ•°={len(matches)}, ä¼˜è´¨={len(good_matches)}")
        
        if len(good_matches) < min_match_count:
            print(f"   âš ï¸ ä¼˜è´¨åŒ¹é…è¿‡å°‘ ({len(good_matches)} < {min_match_count})")
            # ğŸ†• å°è¯•æ¨¡æ¿åŒ¹é…ä½œä¸ºåå¤‡
            if len(good_matches) < min_match_count // 2:
                return _template_matching_fallback(img1, img2, overlap_ratio)
            # åŒ¹é…ç‚¹è¾ƒå°‘ä½†ä¸æ˜¯å®Œå…¨æ²¡æœ‰,ç»§ç»­å°è¯•
            return None, len(good_matches) / max(min_match_count, 1)
        
        # 5. æå–åŒ¹é…ç‚¹åæ ‡
        pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])
        pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])
        
        # ğŸ†• 6. å‡ ä½•çº¦æŸéªŒè¯ - å‚ç›´æ‹¼æ¥æ—¶Xè½´åç§»åº”æ¥è¿‘0
        x_offsets = pts1[:, 0] - pts2[:, 0]
        x_median = np.median(x_offsets)
        x_std = np.std(x_offsets)
        
        # è¿‡æ»¤Xè½´åç§»å¼‚å¸¸çš„ç‚¹(è¶…è¿‡3å€æ ‡å‡†å·®)
        x_inliers_mask = np.abs(x_offsets - x_median) < 3 * max(x_std, 5)
        
        if np.sum(x_inliers_mask) < min_match_count:
            print(f"   âš ï¸ Xè½´çº¦æŸè¿‡æ»¤ååŒ¹é…ç‚¹ä¸è¶³: {np.sum(x_inliers_mask)}")
            # ä¸å®Œå…¨æ‹’ç»,é™ä½ç½®ä¿¡åº¦
            x_penalty = 0.5
        else:
            # åº”ç”¨Xè½´è¿‡æ»¤
            pts1 = pts1[x_inliers_mask]
            pts2 = pts2[x_inliers_mask]
            good_matches = [m for i, m in enumerate(good_matches) if x_inliers_mask[i]]
            x_penalty = 1.0
            print(f"   âœ… Xè½´çº¦æŸè¿‡æ»¤: ä¿ç•™ {len(good_matches)} ä¸ªåŒ¹é…ç‚¹ (X_median={x_median:.1f}px, X_std={x_std:.1f}px)")
        
        # ğŸ†• 7. æ”¹è¿›çš„Yè½´åç§»è®¡ç®— - ä½¿ç”¨RANSACæ€æƒ³
        y_offsets = pts1[:, 1] - pts2[:, 1]
        
        # ä½¿ç”¨æ”¹è¿›çš„å¼‚å¸¸å€¼è¿‡æ»¤(MAD - Median Absolute Deviation)
        if len(y_offsets) >= 4:
            y_median = np.median(y_offsets)
            mad = np.median(np.abs(y_offsets - y_median))
            
            # MAD-based å¼‚å¸¸å€¼æ£€æµ‹(æ›´é²æ£’)
            if mad > 0:
                modified_z_scores = 0.6745 * (y_offsets - y_median) / mad
                y_inliers_mask = np.abs(modified_z_scores) < 3.5
            else:
                # MADä¸º0è¯´æ˜æ‰€æœ‰ç‚¹å‡ ä¹ä¸€è‡´,ç›´æ¥ä½¿ç”¨
                y_inliers_mask = np.ones(len(y_offsets), dtype=bool)
            
            if np.sum(y_inliers_mask) >= 3:
                y_filtered = y_offsets[y_inliers_mask]
                median_offset = np.median(y_filtered)
                std_offset = np.std(y_filtered)
                inlier_ratio = np.sum(y_inliers_mask) / len(y_offsets)
                print(f"   Yè½´RANSAC: å†…ç‚¹æ¯”ä¾‹={inlier_ratio:.1%}, æœ‰æ•ˆç‚¹={np.sum(y_inliers_mask)}/{len(y_offsets)}")
            else:
                # RANSACå¤±è´¥,å›é€€åˆ°å››åˆ†ä½æ•°
                y_sorted = np.sort(y_offsets)
                q1_idx = len(y_sorted) // 4
                q3_idx = 3 * len(y_sorted) // 4
                y_filtered = y_sorted[q1_idx:q3_idx]
                median_offset = np.median(y_filtered)
                std_offset = np.std(y_filtered)
                inlier_ratio = 0.5
                print(f"   Yè½´å››åˆ†ä½: ä½¿ç”¨ä¸­é—´50%çš„ç‚¹")
        else:
            median_offset = np.median(y_offsets)
            std_offset = np.std(y_offsets)
            inlier_ratio = 1.0
        
        print(f"   Yè½´åç§»: median={median_offset:.1f}px, std={std_offset:.1f}px")
        
        # ğŸ†• 8. è®¡ç®—å®é™…offset_yï¼ˆä»img1é¡¶éƒ¨ç®—èµ·ï¼‰
        region1_start = h1 - search_height1
        offset_y = int(region1_start + median_offset)
        
        # ğŸ†• 9. æ”¹è¿›çš„ç½®ä¿¡åº¦è®¡ç®—ï¼ˆå¤šç»´åº¦ç»¼åˆè¯„ä¼°ï¼‰
        # 9.1 åŒ¹é…æ•°é‡ç½®ä¿¡åº¦
        num_confidence = min(len(good_matches) / 50.0, 1.0)
        
        # 9.2 ç¨³å®šæ€§ç½®ä¿¡åº¦(æ ‡å‡†å·®)
        std_confidence = max(0, 1.0 - std_offset / 50.0)
        
        # 9.3 åŒ¹é…è·ç¦»ç½®ä¿¡åº¦
        avg_distance = np.mean([m.distance for m in good_matches])
        dist_confidence = max(0, 1.0 - avg_distance / 100.0)
        
        # ğŸ†• 9.4 å†…ç‚¹æ¯”ä¾‹ç½®ä¿¡åº¦
        inlier_confidence = inlier_ratio
        
        # ğŸ†• 9.5 Xè½´çº¦æŸç½®ä¿¡åº¦
        x_constraint_confidence = 1.0 if abs(x_median) < 10 and x_std < 5 else max(0, 1.0 - abs(x_median) / 50.0)
        
        # ğŸ†• 9.6 ç©ºé—´åˆ†å¸ƒç½®ä¿¡åº¦(åŒ¹é…ç‚¹åº”å‡åŒ€åˆ†å¸ƒ,é¿å…èšé›†)
        if len(good_matches) >= 10:
            pts1_y = pts1[:, 1]
            y_range = np.max(pts1_y) - np.min(pts1_y)
            y_coverage = y_range / gray1.shape[0] if gray1.shape[0] > 0 else 0
            spatial_confidence = min(y_coverage / 0.3, 1.0)  # æœŸæœ›è¦†ç›–è‡³å°‘30%çš„åŒºåŸŸ
        else:
            spatial_confidence = 0.5
        
        # ç»¼åˆç½®ä¿¡åº¦(åŠ æƒå¹³å‡)
        confidence = (
            num_confidence * 0.25 +          # åŒ¹é…æ•°é‡ 25%
            std_confidence * 0.25 +          # ç¨³å®šæ€§ 25%
            dist_confidence * 0.15 +         # è·ç¦» 15%
            inlier_confidence * 0.15 +       # å†…ç‚¹æ¯”ä¾‹ 15%
            x_constraint_confidence * 0.10 + # Xè½´çº¦æŸ 10%
            spatial_confidence * 0.10        # ç©ºé—´åˆ†å¸ƒ 10%
        )
        
        confidence *= x_penalty  # åº”ç”¨Xè½´çº¦æŸæƒ©ç½š
        
        print(f"   ç½®ä¿¡åº¦: {confidence:.3f}")
        print(f"      åŒ¹é…={num_confidence:.2f}, ç¨³å®š={std_confidence:.2f}, è·ç¦»={dist_confidence:.2f}")
        print(f"      å†…ç‚¹={inlier_confidence:.2f}, Xçº¦æŸ={x_constraint_confidence:.2f}, åˆ†å¸ƒ={spatial_confidence:.2f}")
        
        # 9. éªŒè¯åˆç†æ€§ï¼ˆæ”¹è¿›çš„é€»è¾‘ï¼‰
        overlap_height = h1 - offset_y
        
        # 9.1 åŸºæœ¬åˆç†æ€§æ£€æŸ¥
        if overlap_height <= 0:
            print(f"   âŒ æ— é‡å  (overlap={overlap_height}px)")
            confidence *= 0.2
            return offset_y, confidence
        
        if overlap_height >= h2:
            # ç‰¹æ®Šæƒ…å†µï¼šimg2å®Œå…¨åœ¨img1èŒƒå›´å†…ï¼ˆæœ€åä¸€æ¬¡å¾ˆå°çš„æ»šåŠ¨ï¼‰
            # è¿™æ˜¯åˆç†çš„ï¼è®¡ç®—çœŸå®çš„é‡å æ¯”ä¾‹
            overlap_ratio_to_img2 = overlap_height / h2
            
            if overlap_ratio_to_img2 > 1.0:
                # img2å®Œå…¨åŒ…å«åœ¨é‡å åŒºåŸŸå†…
                actual_new_height = offset_y + h2
                
                # æ£€æŸ¥ç‰¹å¾åŒ¹é…çš„è´¨é‡
                if len(good_matches) >= 50 and std_offset < 10:
                    # ç‰¹å¾åŒ¹é…è´¨é‡å¾ˆå¥½ï¼Œç›¸ä¿¡è¿™ä¸ªç»“æœ
                    print(f"   âœ… å°æ»šåŠ¨æ£€æµ‹: offset_y={offset_y}, img2å®Œå…¨åœ¨é‡å åŒºåŸŸå†…")
                    print(f"      img2é«˜åº¦={h2}px, é‡å ={overlap_height}px, æ–°å¢={h2-overlap_height}px")
                    # ä¸æƒ©ç½šç½®ä¿¡åº¦
                    return offset_y, confidence
                else:
                    print(f"   âš ï¸ é‡å å¼‚å¸¸: {overlap_height}px >= img2é«˜åº¦ {h2}pxï¼Œä¸”åŒ¹é…è´¨é‡ä¸è¶³")
                    confidence *= 0.3
                    return offset_y, confidence
        
        # 9.2 æ­£å¸¸æƒ…å†µï¼šè®¡ç®—é‡å æ¯”ä¾‹
        # ä½¿ç”¨img2é«˜åº¦ä½œä¸ºåŸºå‡†ï¼ˆæ›´åˆç†ï¼‰
        overlap_ratio_to_img2 = overlap_height / h2
        
        if overlap_ratio_to_img2 < 0.05:
            # é‡å å¤ªå°‘ï¼ˆ<5%ï¼‰
            print(f"   âš ï¸ é‡å è¿‡å°‘: {overlap_height}px ({overlap_ratio_to_img2:.1%})")
            confidence *= 0.7  # è½»å¾®æƒ©ç½š
        elif overlap_ratio_to_img2 > 0.95:
            # é‡å å¾ˆå¤§ï¼ˆ>95%ï¼‰ï¼Œä½†å¦‚æœç‰¹å¾åŒ¹é…å¥½ï¼Œå¯èƒ½æ˜¯å°æ»šåŠ¨
            if len(good_matches) >= 30 and std_offset < 5:
                print(f"   âœ… å°æ»šåŠ¨: offset_y={offset_y}, é‡å ={overlap_height}px ({overlap_ratio_to_img2:.1%})")
                # ä¸æƒ©ç½š
            else:
                print(f"   âš ï¸ é‡å è¿‡å¤§: {overlap_height}px ({overlap_ratio_to_img2:.1%})")
                confidence *= 0.6
        else:
            # æ­£å¸¸èŒƒå›´ï¼ˆ5%-95%ï¼‰
            print(f"   âœ… é‡å åˆç†: offset_y={offset_y}, é«˜åº¦={overlap_height}px ({overlap_ratio_to_img2:.1%})")
        
        return offset_y, confidence
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾åŒ¹é…å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, 0.0


def _pairwise_stitch_recursive(images: List[np.ndarray],
                               overlap_ratio: float,
                               min_confidence: float,
                               blend: bool,
                               level: int = 0,
                               scroll_distances: List[int] = None) -> np.ndarray:
    """
    é€’å½’å¼ä¸¤ä¸¤é…å¯¹æ‹¼æ¥(åˆ†æ²»æ³•)
    
    å·¥ä½œåŸç†:
      ç¬¬1è½®: [img1+img2, img3+img4, img5+img6, ...]  <- å°å›¾+å°å›¾
      ç¬¬2è½®: [result1+result2, result3+result4, ...]  <- ä¸­å›¾+ä¸­å›¾  
      ç¬¬3è½®: [result1+result2]                        <- å¤§å›¾+å¤§å›¾
    
    ä¼˜åŠ¿:
      âœ… æ¯æ¬¡åŒ¹é…çš„å›¾ç‰‡å¤§å°ç›¸è¿‘,ç‰¹å¾ç‚¹åˆ†å¸ƒå‡è¡¡
      âœ… å‡å°‘ç´¯ç§¯è¯¯å·®,é¿å…å°å›¾ä¸å·¨å¤§ç´¯ç§¯å›¾åŒ¹é…
      âœ… ç¬¦åˆåˆ†æ²»ç®—æ³•æ€æƒ³,æ›´é²æ£’
    
    Args:
        images: OpenCVæ ¼å¼çš„å›¾ç‰‡åˆ—è¡¨
        overlap_ratio: æœç´¢èŒƒå›´æ¯”ä¾‹
        min_confidence: æœ€å°ç½®ä¿¡åº¦
        blend: æ˜¯å¦æ··åˆ
        level: é€’å½’å±‚çº§(ç”¨äºæ—¥å¿—)
        scroll_distances: æ¯æ¬¡æˆªå›¾ä¹‹é—´çš„æ»šåŠ¨è·ç¦»(åƒç´ )
    
    Returns:
        æ‹¼æ¥åçš„OpenCVå›¾åƒ
    """
    if len(images) == 1:
        return images[0]
    
    indent = "  " * level
    print(f"{indent}ğŸ”„ ç¬¬{level+1}è½®é…å¯¹: {len(images)}å¼ å›¾ç‰‡ â†’ {(len(images)+1)//2}å¼ ç»“æœ")
    
    next_level_images = []
    
    # ä¸¤ä¸¤é…å¯¹æ‹¼æ¥
    for i in range(0, len(images), 2):
        if i + 1 < len(images):
            # æœ‰é…å¯¹
            img1 = images[i]
            img2 = images[i + 1]
            h1, h2 = img1.shape[0], img2.shape[0]
            
            print(f"{indent}   ğŸ“ é…å¯¹ {i//2+1}: img{i+1}({h1}px) + img{i+2}({h2}px)")
            
            # ğŸ†• è·å–å½“å‰é…å¯¹çš„æ»šåŠ¨è·ç¦»(ç¬¬i+1å¼ çš„æ»šåŠ¨è·ç¦»)
            scroll_distance = None
            if scroll_distances and level == 0:  # ä»…åœ¨ç¬¬ä¸€è½®ä½¿ç”¨åŸå§‹æ»šåŠ¨è·ç¦»
                # images[i+1]å¯¹åº”cv2_images[i+1],å…¶æ»šåŠ¨è·ç¦»ä¸ºscroll_distances[i+1]
                if i + 1 < len(scroll_distances):
                    scroll_distance = scroll_distances[i + 1]
            
            # ä½¿ç”¨ç‰¹å¾ç‚¹åŒ¹é…
            offset_y, confidence = find_overlap_region(img1, img2, overlap_ratio, scroll_distance=scroll_distance)
            
            if offset_y is not None and confidence >= min_confidence:
                overlap_pixels = h1 - offset_y
                # ä¿®å¤: ä½¿ç”¨ >= è€Œä¸æ˜¯ >, å…è®¸å®Œå…¨é‡å çš„æƒ…å†µ
                if overlap_pixels > 0 and offset_y + h2 >= h1:
                    # æ™ºèƒ½æ‹¼æ¥
                    print(f"{indent}      âœ… æ™ºèƒ½æ‹¼æ¥: overlap={overlap_pixels}px, conf={confidence:.3f}")
                    result = _blend_stitch(img1, img2, offset_y, overlap_pixels, blend)
                    next_level_images.append(result)
                else:
                    # æ— æ•ˆé‡å , ç®€å•æ‹¼æ¥
                    print(f"{indent}      âš ï¸ æ— æ•ˆé‡å , ç®€å•æ‹¼æ¥")
                    result = _simple_append(img1, img2)
                    next_level_images.append(result)
            else:
                # åŒ¹é…å¤±è´¥, ç®€å•æ‹¼æ¥
                conf_str = f"{confidence:.3f}" if confidence > 0 else "N/A"
                print(f"{indent}      âš ï¸ åŒ¹é…å¤±è´¥ (conf={conf_str}), ç®€å•æ‹¼æ¥")
                result = _simple_append(img1, img2)
                next_level_images.append(result)
        else:
            # å¥‡æ•°ä¸ª, æœ€åä¸€å¼ å•ç‹¬ä¿ç•™
            print(f"{indent}   ğŸ“Œ ä¿ç•™: img{i+1} (æ— é…å¯¹)")
            next_level_images.append(images[i])
    
    # é€’å½’å¤„ç†ä¸‹ä¸€è½®
    return _pairwise_stitch_recursive(
        next_level_images, 
        overlap_ratio, 
        min_confidence, 
        blend, 
        level + 1,
        scroll_distances=None  # åç»­è½®æ¬¡ä¸å†ä½¿ç”¨æ»šåŠ¨è·ç¦»
    )


def _calculate_overlap_ratio(img1: np.ndarray, img2: np.ndarray, 
                            search_ratio: float = 0.5) -> float:
    """
    è®¡ç®—ä¸¤å¼ å›¾ç‰‡çš„é‡å¤ç‡
    
    Args:
        img1: ç¬¬ä¸€å¼ å›¾ç‰‡
        img2: ç¬¬äºŒå¼ å›¾ç‰‡
        search_ratio: æœç´¢èŒƒå›´æ¯”ä¾‹
        
    Returns:
        é‡å¤ç‡ (0.0-1.0)
    """
    try:
        h1, h2 = img1.shape[0], img2.shape[0]
        
        # ä½¿ç”¨find_overlap_regionè®¡ç®—é‡å 
        offset_y, confidence = find_overlap_region(img1, img2, search_ratio)
        
        print(f"   ğŸ” é‡å¤ç‡è®¡ç®—: offset_y={offset_y}, confidence={confidence:.3f}")
        
        if offset_y is None or confidence < 0.3:
            print(f"   âŒ åŒ¹é…å¤±è´¥: offset_y={offset_y}, confidence={confidence}")
            return 0.0
        
        # è®¡ç®—é‡å åƒç´ 
        overlap_pixels = h1 - offset_y
        print(f"   ğŸ“ é‡å è®¡ç®—: h1={h1}, offset_y={offset_y} â†’ overlap={overlap_pixels}px")
        
        if overlap_pixels <= 0:
            print(f"   âŒ è´Ÿé‡å : overlap_pixels={overlap_pixels}")
            return 0.0
        
        # ğŸ”§ ä¿®æ­£é‡å¤ç‡è®¡ç®—ï¼šåº”è¯¥ç”¨è¾ƒå°çš„å›¾ä½œä¸ºåŸºå‡†
        min_height = min(h1, h2)
        overlap_ratio = overlap_pixels / min_height
        
        print(f"   ğŸ“Š é‡å¤ç‡: {overlap_pixels}/{min_height} = {overlap_ratio:.1%}")
        
        # é™åˆ¶åœ¨0-1èŒƒå›´å†…
        return min(max(overlap_ratio, 0.0), 1.0)
        
    except Exception as e:
        print(f"   è®¡ç®—é‡å¤ç‡å¤±è´¥: {e}")
        return 0.0


def _filter_duplicate_images(cv2_images: List[np.ndarray], 
                             high_threshold: float = 0.6,
                             low_threshold: float = 0.2,
                             identical_threshold: float = 0.95) -> List[np.ndarray]:
    """
    è¿‡æ»¤é‡å¤çš„å›¾ç‰‡ï¼ˆæ”¹è¿›ç‰ˆ - æ”¯æŒå®Œå…¨é‡å¤æ£€æµ‹ï¼ŒåŒ…æ‹¬æœ€åä¸€å¼ ï¼‰
    
    è§„åˆ™ï¼š
      1. æ ‡å‡†è·³è¿‡ï¼šå¦‚æœå›¾iä¸å›¾i+1çš„é‡å¤ç‡>60%ï¼Œä¸”å›¾iä¸å›¾i+2çš„é‡å¤ç‡>20%ï¼Œ
         åˆ™è·³è¿‡å›¾i+1ï¼ˆè®¤ä¸ºå›¾i+1æ˜¯é‡å¤çš„ä¸­é—´å¸§ï¼‰
      2. å®Œå…¨é‡å¤è·³è¿‡ï¼šå¦‚æœå›¾iä¸å›¾i+1çš„é‡å¤ç‡>95%ï¼ˆå®Œå…¨é‡å¤ï¼‰ï¼Œåˆ™å…è®¸è¿ç»­è·³è¿‡
      3. æœ€åä¸€å¼ ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæœ€åä¸€å¼ ä¸å€’æ•°ç¬¬äºŒå¼ å®Œå…¨é‡å¤ï¼ˆ>95%ï¼‰ï¼Œä¹Ÿä¼šè¢«è·³è¿‡
      4. ä¸å…è®¸è¿ç»­è·³è¿‡2å¼ å›¾ç‰‡ï¼ˆé™¤éæ˜¯å®Œå…¨é‡å¤ï¼‰
      5. è¿‡æ»¤åè‡³å°‘ä¿ç•™2å¼ å›¾ç‰‡ï¼ˆå¦åˆ™æ— æ³•æ‹¼æ¥ï¼‰
    
    Args:
        cv2_images: OpenCVæ ¼å¼çš„å›¾ç‰‡åˆ—è¡¨
        high_threshold: é«˜é‡å¤ç‡é˜ˆå€¼ï¼ˆé»˜è®¤0.6ï¼Œå³60%ï¼‰
        low_threshold: ä½é‡å¤ç‡é˜ˆå€¼ï¼ˆé»˜è®¤0.2ï¼Œå³20%ï¼‰
        identical_threshold: å®Œå…¨é‡å¤é˜ˆå€¼ï¼ˆé»˜è®¤0.95ï¼Œå³95%ï¼‰
        
    Returns:
        è¿‡æ»¤åçš„å›¾ç‰‡åˆ—è¡¨
    """
    if len(cv2_images) <= 2:
        return cv2_images
    
    print(f"\nğŸ” æ£€æµ‹é‡å¤å›¾ç‰‡ (é˜ˆå€¼: è¿ç»­>{high_threshold*100:.0f}% ä¸”éš”ä¸€>{low_threshold*100:.0f}%, å®Œå…¨é‡å¤>{identical_threshold*100:.0f}%)")
    
    filtered = []
    skip_indices = set()
    last_skipped = False  # ğŸ†• è®°å½•ä¸Šä¸€å¼ æ˜¯å¦è¢«è·³è¿‡
    
    i = 0
    while i < len(cv2_images):
        if i in skip_indices:
            i += 1
            continue
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡ä¸‹ä¸€å¼ å›¾
        if i + 1 < len(cv2_images):
            # è®¡ç®— img[i] å’Œ img[i+1] çš„é‡å¤ç‡
            ratio_consecutive = _calculate_overlap_ratio(cv2_images[i], cv2_images[i+1])
            
            # å¦‚æœæœ‰ i+2ï¼Œä¹Ÿè®¡ç®—å®ƒçš„é‡å¤ç‡
            if i + 2 < len(cv2_images):
                ratio_skip_one = _calculate_overlap_ratio(cv2_images[i], cv2_images[i+2])
                print(f"   å›¾{i+1}-å›¾{i+2}: {ratio_consecutive*100:.1f}%, å›¾{i+1}-å›¾{i+3}: {ratio_skip_one*100:.1f}%", end="")
            else:
                # æœ€åä¸¤å¼ å›¾ï¼Œåªèƒ½æ£€æµ‹è¿ç»­é‡å¤
                ratio_skip_one = 0.0
                print(f"   å›¾{i+1}-å›¾{i+2}: {ratio_consecutive*100:.1f}% (æœ€åä¸€å¼ )", end="")
            
            # ğŸ†• æ£€æµ‹æ˜¯å¦ä¸ºå®Œå…¨é‡å¤çš„å›¾ï¼ˆä¸€æ¨¡ä¸€æ ·ï¼‰
            is_identical = ratio_consecutive > identical_threshold
            
            # ğŸ†• åˆ¤æ–­æ˜¯å¦å¯ä»¥è·³è¿‡
            if i + 2 < len(cv2_images):
                # æ ‡å‡†æƒ…å†µï¼šéœ€è¦åŒæ—¶æ»¡è¶³è¿ç»­>60% ä¸”éš”ä¸€>20%
                can_skip = (
                    ratio_consecutive > high_threshold and 
                    ratio_skip_one > low_threshold and
                    (not last_skipped or is_identical)  # å¦‚æœæ˜¯å®Œå…¨é‡å¤ï¼Œå…è®¸è¿ç»­è·³è¿‡
                )
            else:
                # ç‰¹æ®Šæƒ…å†µï¼šæœ€åä¸€å¼ å›¾ï¼Œåªéœ€æ»¡è¶³å®Œå…¨é‡å¤æ¡ä»¶
                can_skip = is_identical and (not last_skipped or is_identical)
            
            # ğŸ†• æ£€æŸ¥è·³è¿‡åæ˜¯å¦è‡³å°‘è¿˜æœ‰2å¼ å›¾ç‰‡
            potential_remaining = len(cv2_images) - len(skip_indices) - 1  # -1æ˜¯å› ä¸ºè¦è·³è¿‡å½“å‰çš„i+1
            if potential_remaining < 2:
                can_skip = False
                print(f" â†’ âš ï¸ ä¸èƒ½è·³è¿‡ï¼ˆè·³è¿‡ååªå‰©{potential_remaining}å¼ å›¾ç‰‡ï¼‰", end="")
            
            # åˆ¤æ–­æ˜¯å¦æ»¡è¶³è·³è¿‡æ¡ä»¶
            if can_skip:
                if is_identical:
                    print(f" â†’ âŒ è·³è¿‡å›¾{i+2}ï¼ˆå®Œå…¨é‡å¤ï¼‰")
                else:
                    print(f" â†’ âŒ è·³è¿‡å›¾{i+2}ï¼ˆé‡å¤ï¼‰")
                skip_indices.add(i + 1)
                filtered.append(cv2_images[i])
                last_skipped = True  # ğŸ†• æ ‡è®°å·²è·³è¿‡
                i += 1
                continue
            else:
                if ratio_consecutive > high_threshold:
                    if i + 2 >= len(cv2_images):
                        # æœ€åä¸€å¼ ï¼Œä¸æ»¡è¶³å®Œå…¨é‡å¤æ¡ä»¶
                        print(f" â†’ âœ… ä¿ç•™ï¼ˆæœ€åä¸€å¼ ï¼Œé‡å¤ç‡{ratio_consecutive*100:.1f}%æœªè¾¾åˆ°å®Œå…¨é‡å¤é˜ˆå€¼ï¼‰")
                    elif ratio_skip_one <= low_threshold:
                        print(f" â†’ âœ… ä¿ç•™ï¼ˆéš”ä¸€å›¾é‡å¤ç‡ä¸è¶³ï¼‰")
                    elif last_skipped and not is_identical:
                        print(f" â†’ âš ï¸ ä¿ç•™ï¼ˆä¸å…è®¸è¿ç»­è·³è¿‡ï¼‰")
                    else:
                        print(f" â†’ âœ… ä¿ç•™")
                else:
                    print(f" â†’ âœ… ä¿ç•™")
                last_skipped = False  # ğŸ†• é‡ç½®è·³è¿‡æ ‡è®°
        else:
            last_skipped = False  # ğŸ†• é‡ç½®è·³è¿‡æ ‡è®°
        
        filtered.append(cv2_images[i])
        i += 1
    
    removed_count = len(cv2_images) - len(filtered)
    if removed_count > 0:
        print(f"âœ… è¿‡æ»¤å®Œæˆ: ç§»é™¤äº† {removed_count} å¼ é‡å¤å›¾ç‰‡ï¼Œä¿ç•™ {len(filtered)} å¼ ")
    else:
        print(f"âœ… æœªå‘ç°é‡å¤å›¾ç‰‡ï¼Œä¿ç•™å…¨éƒ¨ {len(filtered)} å¼ ")
    
    return filtered


def smart_stitch_vertical(images: List[Union[Image.Image, np.ndarray]],
                         overlap_ratio: float = 0.3,
                         min_confidence: float = 0.5,
                         blend: bool = True,
                         strategy: str = 'pairwise',
                         filter_duplicates: bool = True,
                         duplicate_high_threshold: float = 0.6,
                         duplicate_low_threshold: float = 0.2,
                         duplicate_identical_threshold: float = 0.95,
                         scroll_distances: List[int] = None) -> Image.Image:
    """
    æ™ºèƒ½å‚ç›´æ‹¼æ¥å›¾ç‰‡ï¼Œä½¿ç”¨ç‰¹å¾ç‚¹åŒ¹é…è‡ªåŠ¨è¯†åˆ«é‡å åŒºåŸŸï¼ˆæ”¯æŒæ»šåŠ¨è·ç¦»è¾…åŠ©ï¼‰
    
    Args:
        images: å›¾ç‰‡åˆ—è¡¨ï¼ˆPIL Imageæˆ–numpyæ•°ç»„ï¼‰
        overlap_ratio: æœç´¢èŒƒå›´æ¯”ä¾‹ï¼ˆ0.3è¡¨ç¤ºåœ¨30%èŒƒå›´å†…æœç´¢ï¼‰
        min_confidence: æœ€å°ç½®ä¿¡åº¦ï¼Œä½äºæ­¤å€¼åˆ™é™çº§å¤„ç†
        blend: æ˜¯å¦åœ¨é‡å åŒºåŸŸè¿›è¡Œalphaæ··åˆ
        strategy: æ‹¼æ¥ç­–ç•¥
            - 'pairwise' (æ¨è): ä¸¤ä¸¤é…å¯¹æ‹¼æ¥ï¼Œæ¯æ¬¡åˆæˆçš„å›¾å¤§å°ç›¸è¿‘ï¼ŒåŒ¹é…æ›´å‡†ç¡®
            - 'sequential': é¡ºåºç´¯ç§¯æ‹¼æ¥ï¼Œä¼ ç»Ÿæ–¹å¼
        filter_duplicates: æ˜¯å¦è¿‡æ»¤é‡å¤å›¾ç‰‡ï¼ˆé»˜è®¤Trueï¼‰
        duplicate_high_threshold: è¿ç»­ä¸¤å›¾çš„é«˜é‡å¤ç‡é˜ˆå€¼ï¼ˆé»˜è®¤0.6ï¼Œå³60%ï¼‰
        duplicate_low_threshold: éš”ä¸€å›¾çš„ä½é‡å¤ç‡é˜ˆå€¼ï¼ˆé»˜è®¤0.2ï¼Œå³20%ï¼‰
        duplicate_identical_threshold: å®Œå…¨é‡å¤é˜ˆå€¼ï¼ˆé»˜è®¤0.95ï¼Œå³95%ï¼Œå…è®¸è¿ç»­è·³è¿‡ï¼‰
        scroll_distances: ğŸ†• æ»šåŠ¨è·ç¦»åˆ—è¡¨ï¼ˆåƒç´ ï¼‰ï¼Œç”¨äºåˆå§‹ä¼°è®¡ï¼Œå¯é€‰
        
    Returns:
        æ‹¼æ¥åçš„PIL Image
    
    æ‹¼æ¥ç­–ç•¥è¯´æ˜:
        pairwise (ä¸¤ä¸¤é…å¯¹):
            ç¬¬1è½®: [img1+img2, img3+img4, ...]  <- å°å›¾+å°å›¾
            ç¬¬2è½®: [result1+result2, ...]        <- ä¸­å›¾+ä¸­å›¾
            ä¼˜åŠ¿: å›¾ç‰‡å¤§å°ç›¸è¿‘ï¼Œç‰¹å¾ç‚¹åˆ†å¸ƒå‡è¡¡ï¼Œå‡å°‘ç´¯ç§¯è¯¯å·®
        
        sequential (é¡ºåºç´¯ç§¯):
            ç¬¬1æ¬¡: img1 + img2 = result1
            ç¬¬2æ¬¡: result1 + img3 = result2      <- å¤§å›¾+å°å›¾
            ç¬¬3æ¬¡: result2 + img4 = result3      <- æ›´å¤§å›¾+å°å›¾
            ç¼ºç‚¹: åæœŸå¤§å°å·®å¼‚å¤§ï¼Œå¯èƒ½å½±å“åŒ¹é…ç²¾åº¦
    """
    if not images:
        raise ValueError("å›¾ç‰‡åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    
    if len(images) == 1:
        if isinstance(images[0], np.ndarray):
            return cv2_to_pil(images[0])
        return images[0]
    
    print(f"\n{'='*60}")
    print(f"ğŸ¯ å¼€å§‹æ™ºèƒ½æ‹¼æ¥: {len(images)} å¼ å›¾ç‰‡")
    print(f"   ç®—æ³•: ORBç‰¹å¾ç‚¹åŒ¹é… + RANSAC")
    print(f"   ç­–ç•¥: {strategy.upper()}")
    print(f"   å‚æ•°: min_confidence={min_confidence}, blend={blend}")
    
    # ğŸ†• æ˜¾ç¤ºæ»šåŠ¨è·ç¦»ä¿¡æ¯
    if scroll_distances and len(scroll_distances) > 0:
        print(f"   ğŸ†• æ»šåŠ¨è·ç¦»è¾…åŠ©: å¯ç”¨ ({len(scroll_distances)} ä¸ªè·ç¦»è®°å½•)")
        print(f"      æ€»æ»šåŠ¨è·ç¦»: {sum(scroll_distances)}px, å¹³å‡: {sum(scroll_distances)/len(scroll_distances):.1f}px/æ¬¡")
    else:
        print(f"   æ»šåŠ¨è·ç¦»è¾…åŠ©: æœªå¯ç”¨ (çº¯å›¾åƒåŒ¹é…æ¨¡å¼)")
    
    if filter_duplicates:
        print(f"   é‡å¤è¿‡æ»¤: å¯ç”¨ (è¿ç»­>{duplicate_high_threshold*100:.0f}% ä¸”éš”ä¸€>{duplicate_low_threshold*100:.0f}%, å®Œå…¨é‡å¤>{duplicate_identical_threshold*100:.0f}%)")
    print(f"{'='*60}")
    
    # è½¬æ¢æ‰€æœ‰å›¾ç‰‡ä¸ºOpenCVæ ¼å¼
    cv2_images = []
    for img in images:
        if isinstance(img, Image.Image):
            cv2_images.append(pil_to_cv2(img))
        else:
            cv2_images.append(img)
    
    # ç¡®ä¿æ‰€æœ‰å›¾ç‰‡å®½åº¦ä¸€è‡´
    widths = [img.shape[1] for img in cv2_images]
    if len(set(widths)) > 1:
        print(f"âš ï¸ å›¾ç‰‡å®½åº¦ä¸ä¸€è‡´: {set(widths)}ï¼Œè°ƒæ•´ä¸ºæœ€å°å®½åº¦")
        min_width = min(widths)
        cv2_images = [img[:, :min_width] for img in cv2_images]
    
    # è¿‡æ»¤é‡å¤å›¾ç‰‡
    if filter_duplicates and len(cv2_images) > 2:
        cv2_images = _filter_duplicate_images(
            cv2_images, 
            high_threshold=duplicate_high_threshold,
            low_threshold=duplicate_low_threshold,
            identical_threshold=duplicate_identical_threshold
        )
        
        # å¦‚æœè¿‡æ»¤ååªå‰©ä¸€å¼ å›¾ï¼Œç›´æ¥è¿”å›
        if len(cv2_images) == 1:
            print(f"\nâš ï¸ è¿‡æ»¤ååªå‰©1å¼ å›¾ç‰‡ï¼Œç›´æ¥è¿”å›")
            return cv2_to_pil(cv2_images[0])
    
    # æ ¹æ®ç­–ç•¥é€‰æ‹©æ‹¼æ¥æ–¹å¼
    if strategy == 'pairwise':
        print(f"\nğŸ“Š ä½¿ç”¨ä¸¤ä¸¤é…å¯¹æ‹¼æ¥ç­–ç•¥ (æ¨è)")
        print(f"   ä¼˜åŠ¿: å›¾ç‰‡å¤§å°ç›¸è¿‘ï¼ŒåŒ¹é…æ›´å‡†ç¡®ï¼Œå‡å°‘ç´¯ç§¯è¯¯å·®\n")
        result = _pairwise_stitch_recursive(
            cv2_images, 
            overlap_ratio, 
            min_confidence, 
            blend, 
            level=0,
            scroll_distances=scroll_distances  # ğŸ†• ä¼ é€’æ»šåŠ¨è·ç¦»
        )
        print(f"\n{'='*60}")
        print(f"âœ… ä¸¤ä¸¤é…å¯¹æ‹¼æ¥å®Œæˆ!")
        print(f"   æœ€ç»ˆå°ºå¯¸: {result.shape[1]} x {result.shape[0]}")
        print(f"{'='*60}\n")
        
    else:  # sequential
        print(f"\nğŸ“Š ä½¿ç”¨é¡ºåºç´¯ç§¯æ‹¼æ¥ç­–ç•¥ (ä¼ ç»Ÿæ–¹å¼)\n")
        result = _sequential_stitch(
            cv2_images,
            overlap_ratio,
            min_confidence,
            blend,
            scroll_distances  # ğŸ†• ä¼ é€’æ»šåŠ¨è·ç¦»
        )
    
    # è½¬æ¢å›PIL Image
    return cv2_to_pil(result)


def _sequential_stitch(cv2_images: List[np.ndarray],
                      overlap_ratio: float,
                      min_confidence: float,
                      blend: bool,
                      scroll_distances: List[int] = None) -> np.ndarray:
    """
    é¡ºåºç´¯ç§¯æ‹¼æ¥(åŸæœ‰é€»è¾‘)
    
    ç¬¬1æ¬¡: img1 + img2 = result1
    ç¬¬2æ¬¡: result1 + img3 = result2
    ç¬¬3æ¬¡: result2 + img4 = result3
    ...
    
    Args:
        cv2_images: OpenCVæ ¼å¼çš„å›¾ç‰‡åˆ—è¡¨
        overlap_ratio: æœç´¢èŒƒå›´æ¯”ä¾‹
        min_confidence: æœ€å°ç½®ä¿¡åº¦
        blend: æ˜¯å¦å¯ç”¨ç¾½åŒ–èåˆ
        scroll_distances: æ¯æ¬¡æˆªå›¾ä¹‹é—´çš„æ»šåŠ¨è·ç¦»(åƒç´ )
    
    Returns:
        æ‹¼æ¥åçš„å›¾åƒ(OpenCVæ ¼å¼)
    """
    result = cv2_images[0].copy()
    success_count = 0
    fallback_count = 0
    
    for i in range(1, len(cv2_images)):
        print(f"\nğŸ“ æ‹¼æ¥ç¬¬ {i}/{len(cv2_images)-1} å¯¹å›¾ç‰‡...")
        
        img2 = cv2_images[i]
        h1, w1 = result.shape[:2]
        h2, w2 = img2.shape[:2]
        
        # ğŸ†• è·å–å½“å‰æˆªå›¾çš„æ»šåŠ¨è·ç¦»
        scroll_distance = scroll_distances[i] if (scroll_distances and i < len(scroll_distances)) else None
        
        # ä½¿ç”¨ç‰¹å¾ç‚¹åŒ¹é…æŸ¥æ‰¾é‡å 
        offset_y, confidence = find_overlap_region(result, img2, overlap_ratio, scroll_distance=scroll_distance)
        
        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨æ™ºèƒ½æ‹¼æ¥
        if offset_y is not None and confidence >= min_confidence:
            # æ™ºèƒ½æ‹¼æ¥æˆåŠŸ
            success_count += 1
            
            overlap_pixels = h1 - offset_y
            
            # éªŒè¯åˆç†æ€§ï¼ˆæ”¹è¿›ç‰ˆï¼‰
            if overlap_pixels <= 0:
                print(f"   âš ï¸ æ— é‡å  ({overlap_pixels}px)ï¼Œé™çº§ä¸ºç®€å•æ‹¼æ¥")
                fallback_count += 1
                result = _simple_append(result, img2)
                continue
            
            # å…è®¸overlap >= h2çš„æƒ…å†µï¼ˆå°æ»šåŠ¨ï¼‰
            if overlap_pixels >= h2:
                # img2å®Œå…¨åœ¨é‡å åŒºåŸŸå†…ï¼Œè¿™æ˜¯åˆç†çš„å°æ»šåŠ¨
                print(f"   â„¹ï¸ å°æ»šåŠ¨åœºæ™¯: img2({h2}px)å®Œå…¨åœ¨é‡å åŒºåŸŸ({overlap_pixels}px)å†…")
                # ç»§ç»­æ‰§è¡Œæ™ºèƒ½æ‹¼æ¥
            
            new_height = offset_y + h2
            
            # ä¿®å¤: ä½¿ç”¨ < è€Œä¸æ˜¯ <=ï¼Œå…è®¸ new_height == h1 çš„æƒ…å†µï¼ˆå®Œå…¨é‡å ï¼‰
            if new_height < h1:
                print(f"   âš ï¸ æ–°é«˜åº¦å¼‚å¸¸ ({new_height} < {h1})ï¼Œé™çº§ä¸ºç®€å•æ‹¼æ¥")
                fallback_count += 1
                result = _simple_append(result, img2)
                continue
            
            # æ‰§è¡Œæ™ºèƒ½æ‹¼æ¥
            overlap_ratio_info = (overlap_pixels / h2 * 100) if h2 > 0 else 0
            print(f"   âœ… ä½¿ç”¨æ™ºèƒ½æ‹¼æ¥: overlap={overlap_pixels}px ({overlap_ratio_info:.1f}%), new_height={new_height}px")
            result = _blend_stitch(result, img2, offset_y, overlap_pixels, blend)
            
        else:
            # é™çº§ä¸ºç®€å•æ‹¼æ¥
            conf_str = f"{confidence:.3f}" if confidence > 0 else "N/A"
            print(f"   âš ï¸ ç‰¹å¾åŒ¹é…å¤±è´¥ (confidence={conf_str})ï¼Œä½¿ç”¨ç®€å•æ‹¼æ¥")
            fallback_count += 1
            result = _simple_append(result, img2)
    
    print(f"\n{'='*60}")
    print(f"âœ… é¡ºåºæ‹¼æ¥å®Œæˆ!")
    print(f"   æœ€ç»ˆå°ºå¯¸: {result.shape[1]} x {result.shape[0]}")
    print(f"   æ™ºèƒ½æ‹¼æ¥: {success_count}/{len(cv2_images)-1}")
    print(f"   ç®€å•æ‹¼æ¥: {fallback_count}/{len(cv2_images)-1}")
    print(f"{'='*60}\n")
    
    # è¿”å›OpenCVå›¾åƒï¼ˆä¸æ˜¯PILï¼‰
    return result



def _blend_stitch(result: np.ndarray, img2: np.ndarray, 
                  offset_y: int, overlap_pixels: int, 
                  use_blend: bool) -> np.ndarray:
    """
    æ‰§è¡Œå¸¦æ··åˆçš„æ™ºèƒ½æ‹¼æ¥ï¼ˆæ”¯æŒoverlap>=h2çš„å°æ»šåŠ¨åœºæ™¯ï¼‰
    
    Args:
        result: å½“å‰ç»“æœå›¾åƒ
        img2: è¦æ‹¼æ¥çš„ä¸‹ä¸€å¼ å›¾åƒ
        offset_y: img2çš„èµ·å§‹Yåæ ‡
        overlap_pixels: é‡å åƒç´ æ•°ï¼ˆå¯èƒ½>=h2ï¼‰
        use_blend: æ˜¯å¦ä½¿ç”¨alphaæ··åˆ
    
    Returns:
        æ‹¼æ¥åçš„å›¾åƒ
    """
    h1, w1 = result.shape[:2]
    h2, w2 = img2.shape[:2]
    new_height = offset_y + h2
    
    # åˆ›å»ºæ–°ç”»å¸ƒ
    if len(result.shape) == 3:
        new_result = np.zeros((new_height, w1, result.shape[2]), dtype=result.dtype)
    else:
        new_result = np.zeros((new_height, w1), dtype=result.dtype)
    
    # å¤åˆ¶resultçš„éé‡å éƒ¨åˆ†
    new_result[:offset_y] = result[:offset_y]
    
    # ç‰¹æ®Šæƒ…å†µï¼šimg2å®Œå…¨åœ¨é‡å åŒºåŸŸå†…ï¼ˆoverlap_pixels >= h2ï¼‰
    if overlap_pixels >= h2:
        print(f"      å°æ»šåŠ¨æ‹¼æ¥: img2å®Œå…¨æ›¿æ¢resultçš„[{offset_y}:{offset_y+h2}]åŒºåŸŸ")
        
        if use_blend and h2 > 10:
            # åœ¨img2çš„æ•´ä¸ªé«˜åº¦å†…è¿›è¡Œæ··åˆ
            blend_height = min(h2, 100)
            
            for y in range(blend_height):
                alpha = y / blend_height
                y_in_result = offset_y + y
                y_in_img2 = y
                
                if y_in_result < h1:
                    new_result[y_in_result] = (
                        result[y_in_result] * (1 - alpha) + 
                        img2[y_in_img2] * alpha
                    ).astype(result.dtype)
            
            # å‰©ä½™éƒ¨åˆ†ç›´æ¥ç”¨img2
            if blend_height < h2:
                end_pos = min(offset_y + h2, h1)
                new_result[offset_y + blend_height:end_pos] = img2[blend_height:end_pos - offset_y]
        else:
            # ç›´æ¥è¦†ç›–
            end_pos = min(offset_y + h2, h1)
            new_result[offset_y:end_pos] = img2[:end_pos - offset_y]
        
        # å¦‚æœimg2è¶…å‡ºäº†resultçš„èŒƒå›´ï¼Œå¤åˆ¶è¶…å‡ºéƒ¨åˆ†
        if offset_y + h2 > h1:
            extra_start = h1 - offset_y
            new_result[h1:] = img2[extra_start:]
        
        return new_result
    
    # æ­£å¸¸æƒ…å†µï¼šoverlap_pixels < h2
    # å¤„ç†é‡å åŒºåŸŸ
    if use_blend and overlap_pixels > 10:
        # Alphaæ··åˆï¼ˆçº¿æ€§æ¸å˜ï¼‰
        blend_height = min(overlap_pixels, 100)  # æœ€å¤šæ··åˆ100åƒç´ 
        
        for y in range(blend_height):
            alpha = y / blend_height
            y_in_result = offset_y + y
            y_in_img2 = y
            
            if y_in_result < h1 and y_in_img2 < h2:
                new_result[y_in_result] = (
                    result[y_in_result] * (1 - alpha) + 
                    img2[y_in_img2] * alpha
                ).astype(result.dtype)
        
        # é‡å åŒºåŸŸçš„å‰©ä½™éƒ¨åˆ†ç›´æ¥ç”¨img2
        if blend_height < overlap_pixels and overlap_pixels < h2:
            new_result[offset_y + blend_height:h1] = img2[blend_height:overlap_pixels]
    else:
        # ä¸æ··åˆï¼Œç›´æ¥ç”¨img2è¦†ç›–é‡å åŒºåŸŸ
        actual_overlap = min(overlap_pixels, h2)
        new_result[offset_y:offset_y + actual_overlap] = img2[:actual_overlap]
    
    # å¤åˆ¶img2çš„éé‡å éƒ¨åˆ†
    if h2 > overlap_pixels:
        new_result[h1:] = img2[overlap_pixels:]
    
    return new_result


def _simple_append(result: np.ndarray, img2: np.ndarray) -> np.ndarray:
    """
    ç®€å•å‚ç›´æ‹¼æ¥ï¼ˆæ— é‡å ï¼‰
    
    Args:
        result: å½“å‰ç»“æœå›¾åƒ
        img2: è¦è¿½åŠ çš„å›¾åƒ
    
    Returns:
        æ‹¼æ¥åçš„å›¾åƒ
    """
    h1, w1 = result.shape[:2]
    h2, w2 = img2.shape[:2]
    
    # ç¡®ä¿å®½åº¦ä¸€è‡´
    min_width = min(w1, w2)
    result = result[:, :min_width]
    img2 = img2[:, :min_width]
    
    # åˆ›å»ºæ–°ç”»å¸ƒ
    if len(result.shape) == 3:
        new_result = np.zeros((h1 + h2, min_width, result.shape[2]), dtype=result.dtype)
    else:
        new_result = np.zeros((h1 + h2, min_width), dtype=result.dtype)
    
    new_result[:h1] = result
    new_result[h1:] = img2
    
    return new_result


def simple_stitch_fallback(images: List[Union[Image.Image, np.ndarray]]) -> Image.Image:
    """ç®€å•å‚ç›´æ‹¼æ¥çš„åå¤‡æ–¹æ¡ˆï¼ˆæ— é‡å ï¼‰"""
    print("ğŸ“Œ ä½¿ç”¨ç®€å•å‚ç›´æ‹¼æ¥ï¼ˆæ— é‡å ï¼‰")
    
    from jietuba_stitch import stitch_images_vertical
    
    pil_images = []
    for img in images:
        if isinstance(img, np.ndarray):
            pil_images.append(cv2_to_pil(img))
        else:
            pil_images.append(img)
    
    return stitch_images_vertical(pil_images, align='left', spacing=0)


def auto_stitch(images: List[Union[Image.Image, np.ndarray, str, Path]],
               mode: str = 'smart',
               overlap_ratio: float = 0.3,
               min_confidence: float = 0.5,
               strategy: str = 'pairwise',
               filter_duplicates: bool = True,
               duplicate_high_threshold: float = 0.6,
               duplicate_low_threshold: float = 0.2,
               duplicate_identical_threshold: float = 0.95,
               scroll_distances: List[int] = None) -> Image.Image:
    """
    è‡ªåŠ¨æ‹¼æ¥å›¾ç‰‡ï¼ˆæ™ºèƒ½æˆ–ç®€å•æ¨¡å¼ï¼‰- æ”¯æŒæ»šåŠ¨è·ç¦»è¾…åŠ©
    
    å‡çº§è¯´æ˜:
      - ğŸ†• æ”¯æŒæ»šåŠ¨è·ç¦»è¾…åŠ©ï¼ˆæ··åˆæ–¹æ¡ˆï¼šç‰©ç†åæ ‡ + å›¾åƒåŒ¹é…ï¼‰
      - ç°åœ¨ä½¿ç”¨ORBç‰¹å¾ç‚¹åŒ¹é…ï¼ˆä¹‹å‰æ˜¯æ¨¡æ¿åŒ¹é…ï¼‰
      - ä¸å†éœ€è¦é¢„ä¼°é‡å æ¯”ä¾‹ï¼ˆoverlap_ratioä»…ç”¨äºæœç´¢èŒƒå›´ï¼‰
      - ç½®ä¿¡åº¦é»˜è®¤é™ä½åˆ°0.5ï¼ˆç‰¹å¾åŒ¹é…æ›´å¯é ï¼‰
      - æ–°å¢ä¸¤ä¸¤é…å¯¹æ‹¼æ¥ç­–ç•¥ï¼ˆé»˜è®¤ï¼‰
      - è‡ªåŠ¨é™çº§ç­–ç•¥ï¼šç‰¹å¾åŒ¹é… â†’ ç®€å•æ‹¼æ¥
      - æ–°å¢é‡å¤å›¾ç‰‡è¿‡æ»¤åŠŸèƒ½ï¼ˆæ”¯æŒå®Œå…¨é‡å¤è¿ç»­è·³è¿‡ï¼‰
    
    Args:
        images: å›¾ç‰‡åˆ—è¡¨ï¼ˆå¯ä»¥æ˜¯PIL Imageã€numpyæ•°ç»„æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
        mode: 'smart'ï¼ˆæ™ºèƒ½è¯†åˆ«ï¼‰æˆ– 'simple'ï¼ˆç®€å•æ‹¼æ¥ï¼‰
        overlap_ratio: æœç´¢èŒƒå›´æ¯”ä¾‹ï¼ˆ0.3è¡¨ç¤ºåœ¨å›¾ç‰‡30%èŒƒå›´å†…æœç´¢ç‰¹å¾ç‚¹ï¼‰
        min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0.5-0.7æ¨èï¼‰
        strategy: æ‹¼æ¥ç­–ç•¥ï¼ˆä»…åœ¨mode='smart'æ—¶æœ‰æ•ˆï¼‰
            - 'pairwise' (æ¨è): ä¸¤ä¸¤é…å¯¹æ‹¼æ¥ï¼Œå‡å°‘ç´¯ç§¯è¯¯å·®
            - 'sequential': é¡ºåºç´¯ç§¯æ‹¼æ¥ï¼Œä¼ ç»Ÿæ–¹å¼
        filter_duplicates: æ˜¯å¦è¿‡æ»¤é‡å¤å›¾ç‰‡ï¼ˆé»˜è®¤Trueï¼‰
        duplicate_high_threshold: è¿ç»­ä¸¤å›¾çš„é«˜é‡å¤ç‡é˜ˆå€¼ï¼ˆé»˜è®¤0.6ï¼Œå³60%ï¼‰
        duplicate_low_threshold: éš”ä¸€å›¾çš„ä½é‡å¤ç‡é˜ˆå€¼ï¼ˆé»˜è®¤0.2ï¼Œå³20%ï¼‰
        duplicate_identical_threshold: å®Œå…¨é‡å¤é˜ˆå€¼ï¼ˆé»˜è®¤0.95ï¼Œå³95%ï¼Œå…è®¸è¿ç»­è·³è¿‡ï¼‰
        scroll_distances: ğŸ†• æ»šåŠ¨è·ç¦»åˆ—è¡¨ï¼ˆåƒç´ ï¼‰ï¼Œç”¨äºåˆå§‹ä¼°è®¡ï¼Œå¯é€‰
        
    Returns:
        æ‹¼æ¥åçš„PIL Image
    """
    # åŠ è½½å›¾ç‰‡
    loaded_images = []
    for img in images:
        if isinstance(img, (str, Path)):
            loaded_images.append(Image.open(img))
        else:
            loaded_images.append(img)
    
    if not loaded_images:
        raise ValueError("æ²¡æœ‰å¯æ‹¼æ¥çš„å›¾ç‰‡")
    
    if mode == 'smart':
        try:
            return smart_stitch_vertical(
                loaded_images, 
                overlap_ratio=overlap_ratio,
                min_confidence=min_confidence,
                blend=True,
                strategy=strategy,
                filter_duplicates=filter_duplicates,
                duplicate_high_threshold=duplicate_high_threshold,
                duplicate_low_threshold=duplicate_low_threshold,
                duplicate_identical_threshold=duplicate_identical_threshold,
                scroll_distances=scroll_distances  # ğŸ†• ä¼ é€’æ»šåŠ¨è·ç¦»
            )
        except Exception as e:
            print(f"âš ï¸ æ™ºèƒ½æ‹¼æ¥å¤±è´¥: {e}")
            print("   é™çº§ä¸ºç®€å•æ‹¼æ¥...")
            return simple_stitch_fallback(loaded_images)
    else:
        return simple_stitch_fallback(loaded_images)


if __name__ == "__main__":
    pass
